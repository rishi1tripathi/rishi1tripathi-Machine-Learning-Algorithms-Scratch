{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment3_q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "351dff18aa0148428883506227da41b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df619b1c6593457cb66bcc58b3fd5b26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa31f77ce2a149079b63b5408ae9c1e7",
              "IPY_MODEL_89bea405b88945e19acacaaa88517570"
            ]
          }
        },
        "df619b1c6593457cb66bcc58b3fd5b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa31f77ce2a149079b63b5408ae9c1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c245da9f44143fba8d6cdcbd91ebbc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6af2ce1e1e064afa9c77479fadefb2d4"
          }
        },
        "89bea405b88945e19acacaaa88517570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abbdc581d22743ea974ea01d256d69b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [07:26&lt;00:00, 381504.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0d7d343d8ca43e6bee6f347efb146ff"
          }
        },
        "8c245da9f44143fba8d6cdcbd91ebbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6af2ce1e1e064afa9c77479fadefb2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abbdc581d22743ea974ea01d256d69b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0d7d343d8ca43e6bee6f347efb146ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5FO4upeq7Hq"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "351dff18aa0148428883506227da41b4",
            "df619b1c6593457cb66bcc58b3fd5b26",
            "fa31f77ce2a149079b63b5408ae9c1e7",
            "89bea405b88945e19acacaaa88517570",
            "8c245da9f44143fba8d6cdcbd91ebbc7",
            "6af2ce1e1e064afa9c77479fadefb2d4",
            "abbdc581d22743ea974ea01d256d69b9",
            "d0d7d343d8ca43e6bee6f347efb146ff"
          ]
        },
        "id": "toitVCEbrE63",
        "outputId": "e4ac473d-c41a-4e1a-b389-7dcbc92e4e3c"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "351dff18aa0148428883506227da41b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ailJ85rO7OAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtdtWhB67I2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a90dd6-fbed-454d-ffd2-99d2d1989e45"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)\n",
        "\n",
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.pad= nn.ZeroPad2d(2)\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.norm= nn.BatchNorm2d(6)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(6* 16 * 16, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.norm(self.conv1(self.pad(x)))))\n",
        "        x = x.view(-1, 6* 16 * 16)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeaFng3rHE5W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaHxBBC27O50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5483d8b9-7970-4867-ab06-c7f173175c70"
      },
      "source": [
        "import torch.optim as optim\n",
        "net1= Net1()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net1.parameters(), lr=0.001, momentum=0.9)\n",
        "net1.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net1(\n",
              "  (pad): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (norm): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1536, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEBLGHG--gCu"
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net1.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoWZ8mQFCtQJ"
      },
      "source": [
        "# Removed batch layer\n",
        "class Net_no_batch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_no_batch, self).__init__()\n",
        "        self.pad= nn.ZeroPad2d(2)\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(6* 16 * 16, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(self.pad(x))))\n",
        "        x = x.view(-1, 6* 16 * 16)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "import torch.optim as optim\n",
        "net_no_batch= Net_no_batch()\n",
        "net_no_batch.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_no_batch.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ubQaosHF8e",
        "outputId": "8685eb5d-bddd-44b7-d48e-85383d3fdb0f"
      },
      "source": [
        "for epoch in range(3):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = net_no_batch(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net_no_batch(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.806\n",
            "[1,  4000] loss: 1.553\n",
            "[1,  6000] loss: 1.508\n",
            "[1,  8000] loss: 1.481\n",
            "[1, 10000] loss: 1.436\n",
            "[1, 12000] loss: 1.399\n",
            "[2,  2000] loss: 1.362\n",
            "[2,  4000] loss: 1.317\n",
            "[2,  6000] loss: 1.335\n",
            "[2,  8000] loss: 1.376\n",
            "[2, 10000] loss: 1.335\n",
            "[2, 12000] loss: 1.355\n",
            "[3,  2000] loss: 1.256\n",
            "[3,  4000] loss: 1.267\n",
            "[3,  6000] loss: 1.291\n",
            "[3,  8000] loss: 1.297\n",
            "[3, 10000] loss: 1.300\n",
            "[3, 12000] loss: 1.306\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 51 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tUwDdHJiPjw"
      },
      "source": [
        "# Fully connected two layers\n",
        "class Net_b(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_b, self).__init__()\n",
        "        self.pad= nn.ZeroPad2d(2)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "        self.norm= nn.BatchNorm2d(16)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16* 16 * 16, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.norm(self.conv1(self.pad(x)))))\n",
        "        x = x.view(-1, 16* 16 * 16)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "import torch.optim as optim\n",
        "net_b= Net_b()\n",
        "net_b.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_b.parameters(), lr=0.001, momentum=0.9)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fA24V1uivo6",
        "outputId": "edb255a6-2d71-4cb1-9514-ff4f2283402f"
      },
      "source": [
        "for epoch in range(3):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = net_b(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net_b(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.770\n",
            "[1,  4000] loss: 1.543\n",
            "[1,  6000] loss: 1.470\n",
            "[1,  8000] loss: 1.396\n",
            "[1, 10000] loss: 1.347\n",
            "[1, 12000] loss: 1.341\n",
            "[2,  2000] loss: 1.250\n",
            "[2,  4000] loss: 1.229\n",
            "[2,  6000] loss: 1.213\n",
            "[2,  8000] loss: 1.224\n",
            "[2, 10000] loss: 1.201\n",
            "[2, 12000] loss: 1.169\n",
            "[3,  2000] loss: 1.119\n",
            "[3,  4000] loss: 1.143\n",
            "[3,  6000] loss: 1.133\n",
            "[3,  8000] loss: 1.127\n",
            "[3, 10000] loss: 1.133\n",
            "[3, 12000] loss: 1.132\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 57 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZbxpB2akLNt"
      },
      "source": [
        "# 2 layer conv,batch,max pool\n",
        "class Net_c(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_c, self).__init__()\n",
        "        self.pad= nn.ZeroPad2d(2)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "        self.norm1= nn.BatchNorm2d(16)\n",
        "        self.norm2= nn.BatchNorm2d(32)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32* 8 * 8, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.norm1(self.conv1(self.pad(x)))))\n",
        "        x = self.pool(F.relu(self.norm2(self.conv2(self.pad(x)))))\n",
        "        x = x.view(-1, 32* 8 * 8)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "import torch.optim as optim\n",
        "net_c= Net_c()\n",
        "net_c.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_c.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlySOmtTlAEl",
        "outputId": "5c198e9c-d8e1-4ff4-95ff-1b222dd66191"
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = net_c(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net_c(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.757\n",
            "[1,  4000] loss: 1.472\n",
            "[1,  6000] loss: 1.359\n",
            "[1,  8000] loss: 1.254\n",
            "[1, 10000] loss: 1.207\n",
            "[1, 12000] loss: 1.133\n",
            "[2,  2000] loss: 1.075\n",
            "[2,  4000] loss: 1.052\n",
            "[2,  6000] loss: 1.040\n",
            "[2,  8000] loss: 1.027\n",
            "[2, 10000] loss: 0.990\n",
            "[2, 12000] loss: 1.002\n",
            "[3,  2000] loss: 0.921\n",
            "[3,  4000] loss: 0.943\n",
            "[3,  6000] loss: 0.922\n",
            "[3,  8000] loss: 0.911\n",
            "[3, 10000] loss: 0.929\n",
            "[3, 12000] loss: 0.899\n",
            "[4,  2000] loss: 0.834\n",
            "[4,  4000] loss: 0.845\n",
            "[4,  6000] loss: 0.865\n",
            "[4,  8000] loss: 0.849\n",
            "[4, 10000] loss: 0.864\n",
            "[4, 12000] loss: 0.841\n",
            "[5,  2000] loss: 0.807\n",
            "[5,  4000] loss: 0.811\n",
            "[5,  6000] loss: 0.784\n",
            "[5,  8000] loss: 0.806\n",
            "[5, 10000] loss: 0.815\n",
            "[5, 12000] loss: 0.814\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 69 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHmx7hDgrBaw"
      },
      "source": [
        "# 3 layer conv,batch,max pool\n",
        "class Net_d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_d, self).__init__()\n",
        "        self.pad= nn.ZeroPad2d(2)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 5)\n",
        "        self.norm1= nn.BatchNorm2d(16)\n",
        "        self.norm2= nn.BatchNorm2d(32)\n",
        "        self.norm3= nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64* 4 * 4, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.norm1(self.conv1(self.pad(x)))))\n",
        "        x = self.pool(F.relu(self.norm2(self.conv2(self.pad(x)))))\n",
        "        x = self.pool(F.relu(self.norm3(self.conv3(self.pad(x)))))\n",
        "        x = x.view(-1, 64* 4 * 4)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "import torch.optim as optim\n",
        "net_d= Net_d()\n",
        "net_d.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_d.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3aaqXfMrVHt",
        "outputId": "9b532bfe-e665-4522-fc40-eea4285c50bb"
      },
      "source": [
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = net_d(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net_d(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.745\n",
            "[1,  4000] loss: 1.475\n",
            "[1,  6000] loss: 1.356\n",
            "[1,  8000] loss: 1.265\n",
            "[1, 10000] loss: 1.202\n",
            "[1, 12000] loss: 1.137\n",
            "[2,  2000] loss: 1.037\n",
            "[2,  4000] loss: 1.021\n",
            "[2,  6000] loss: 0.980\n",
            "[2,  8000] loss: 0.991\n",
            "[2, 10000] loss: 0.964\n",
            "[2, 12000] loss: 0.918\n",
            "[3,  2000] loss: 0.818\n",
            "[3,  4000] loss: 0.841\n",
            "[3,  6000] loss: 0.834\n",
            "[3,  8000] loss: 0.815\n",
            "[3, 10000] loss: 0.829\n",
            "[3, 12000] loss: 0.826\n",
            "[4,  2000] loss: 0.735\n",
            "[4,  4000] loss: 0.743\n",
            "[4,  6000] loss: 0.724\n",
            "[4,  8000] loss: 0.733\n",
            "[4, 10000] loss: 0.737\n",
            "[4, 12000] loss: 0.727\n",
            "[5,  2000] loss: 0.630\n",
            "[5,  4000] loss: 0.648\n",
            "[5,  6000] loss: 0.662\n",
            "[5,  8000] loss: 0.677\n",
            "[5, 10000] loss: 0.668\n",
            "[5, 12000] loss: 0.694\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 73 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPrzFx-JthmV"
      },
      "source": [
        "PATH = './model.pth'\n",
        "torch.save(net_d.state_dict(), PATH)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0OgtJwMuQX-",
        "outputId": "a9c72dcf-f8d4-4a04-ee57-3cec6e1b1419"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "summary(net_d, input_size=(3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         ZeroPad2d-1            [-1, 3, 36, 36]               0\n",
            "            Conv2d-2           [-1, 16, 32, 32]           1,216\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "         MaxPool2d-4           [-1, 16, 16, 16]               0\n",
            "         ZeroPad2d-5           [-1, 16, 20, 20]               0\n",
            "            Conv2d-6           [-1, 32, 16, 16]          12,832\n",
            "       BatchNorm2d-7           [-1, 32, 16, 16]              64\n",
            "         MaxPool2d-8             [-1, 32, 8, 8]               0\n",
            "         ZeroPad2d-9           [-1, 32, 12, 12]               0\n",
            "           Conv2d-10             [-1, 64, 8, 8]          51,264\n",
            "      BatchNorm2d-11             [-1, 64, 8, 8]             128\n",
            "        MaxPool2d-12             [-1, 64, 4, 4]               0\n",
            "           Linear-13                   [-1, 64]          65,600\n",
            "           Linear-14                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 131,786\n",
            "Trainable params: 131,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.61\n",
            "Params size (MB): 0.50\n",
            "Estimated Total Size (MB): 1.12\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPqQSn7TvrCM"
      },
      "source": [
        "accuracy=[]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "net_d= Net_d()\n",
        "net_d.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_d.parameters(), lr=0.001, momentum=0.9)\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    correct = 0.0\n",
        "    total = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net_d(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    for data in testloader:\n",
        "        images_test, labels_test = data[0].to(device), data[1].to(device)\n",
        "        outputs_test = net_d(images_test)\n",
        "        _, predicted = torch.max(outputs_test.data, 1)\n",
        "        total += labels_test.size(0)\n",
        "        correct += (predicted == labels_test).sum().item()\n",
        "    accuracy.append(100 * correct / total)\n",
        "\n",
        "      \n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cRocbEdGw-SJ",
        "outputId": "7a5a2f3d-0785-490e-e321-3c33c2c6b078"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epochs=[1,2,3,4,5]\n",
        "plt.plot(epochs,accuracy)\n",
        "plt.title('title name')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('test-accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
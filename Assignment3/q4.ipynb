{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsT1Qr4wgJrK"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIIiX_xYqq6U"
      },
      "source": [
        "\n",
        "trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transforms.ToTensor())\n",
        "testset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPa_BbMppbum"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class SiameseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc3 = nn.Linear(512, 2)\n",
        "    def forward(self, x1, x2):\n",
        "        y1 = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x1)))))\n",
        "        y2 = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x2)))))\n",
        "        return y1, y2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pirAsC2yCjq"
      },
      "source": [
        "def contrastiveLoss(y1, y2, label):\n",
        "      d = nn.functional.pairwise_distance(y1, y1)\n",
        "      margin =3.0\n",
        "      return torch.mean(((label) * torch.pow(d, 2)) + (1 - label) * torch.pow(torch.clamp(margin - d, min=0.0), 2))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPt9SjZc2ggw"
      },
      "source": [
        "def train(model,optimizer,criterion=contrastiveLoss):\n",
        "  for epc in range(50):\n",
        "      running_loss=0.0\n",
        "      train_iter = iter(trainloader)\n",
        "      while True:\n",
        "        try:\n",
        "          x1, label_1 = next(train_iter)\n",
        "          x2, label_2 = next(train_iter)\n",
        "          \n",
        "          label_1=label_1.to(device)\n",
        "          label_2=label_2.to(device)\n",
        "          dim1= list(label_1.shape)\n",
        "          dim2= list(label_2.shape)\n",
        "          if dim1 != dim2:\n",
        "              break\n",
        "          label =torch.eq(label_1,label_2).to(device)\n",
        "          label = label.type(torch.cuda.FloatTensor)\n",
        "          x1 = x1.view(x1.size(0), -1)\n",
        "          x2 = x2.view(x2.size(0), -1)\n",
        "          x1=x1.to(device)\n",
        "          x2=x2.to(device)\n",
        "          y1, y2 = model(x1, x2)\n",
        "          loss = criterion(x1, x2,label)\n",
        "          loss = Variable(loss, requires_grad=True)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss+=  loss.item()\n",
        "        except StopIteration:\n",
        "          break\n",
        "      print('Epoch: %d Loss: %.3f' % (epc, running_loss/len(trainloader)))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_lUVDtR2lv6"
      },
      "source": [
        "def test(model,optimizer,criterion=contrastiveLoss):\n",
        "   test_iter = iter(testloader)\n",
        "   running_loss=0.0\n",
        "   while True:\n",
        "        try:\n",
        "          x1, label_1 = next(test_iter)\n",
        "          x2, label_2 = next(test_iter)\n",
        "          \n",
        "          label_1.to(device)\n",
        "          label_2.to(device)\n",
        "          dim1= list(label_1.shape)\n",
        "          dim2= list(label_2.shape)\n",
        "          if dim1 != dim2:\n",
        "              break\n",
        "          label =torch.eq(label_1,label_2).to(device)\n",
        "          label = label.type(torch.cuda.FloatTensor)\n",
        "          x1 = x1.view(x1.size(0), -1)\n",
        "          x2 = x2.view(x2.size(0), -1)\n",
        "          x1=x1.to(device)\n",
        "          x2=x2.to(device)\n",
        "          y1, y2 = model(x1, x2)\n",
        "          loss = criterion(x1, x2,label)\n",
        "          loss = Variable(loss, requires_grad=True)\n",
        "          loss.backward()\n",
        "          running_loss+=loss.item()\n",
        "          optimizer.step()  \n",
        "        except StopIteration:\n",
        "          break\n",
        "   print('Test Loss: %.3f' % (running_loss/len(testloader)))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeDcwt_l3eMm",
        "outputId": "86f19502-7e02-4357-ec99-f30f495088a9"
      },
      "source": [
        "# // Contrastive Loss\n",
        "sim=SiameseModel()\n",
        "sim.to(device)\n",
        "optimizer=torch.optim.SGD(sim.parameters(), lr = 0.01)\n",
        "train(sim,optimizer,contrastiveLoss)\n",
        "test(sim,optimizer,contrastiveLoss)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 0.139\n",
            "Epoch: 1 Loss: 0.147\n",
            "Epoch: 2 Loss: 0.137\n",
            "Epoch: 3 Loss: 0.137\n",
            "Epoch: 4 Loss: 0.139\n",
            "Epoch: 5 Loss: 0.139\n",
            "Epoch: 6 Loss: 0.144\n",
            "Epoch: 7 Loss: 0.142\n",
            "Epoch: 8 Loss: 0.142\n",
            "Epoch: 9 Loss: 0.137\n",
            "Epoch: 10 Loss: 0.132\n",
            "Epoch: 11 Loss: 0.142\n",
            "Epoch: 12 Loss: 0.137\n",
            "Epoch: 13 Loss: 0.152\n",
            "Epoch: 14 Loss: 0.147\n",
            "Epoch: 15 Loss: 0.129\n",
            "Epoch: 16 Loss: 0.154\n",
            "Epoch: 17 Loss: 0.134\n",
            "Epoch: 18 Loss: 0.144\n",
            "Epoch: 19 Loss: 0.144\n",
            "Epoch: 20 Loss: 0.137\n",
            "Epoch: 21 Loss: 0.142\n",
            "Epoch: 22 Loss: 0.144\n",
            "Epoch: 23 Loss: 0.142\n",
            "Epoch: 24 Loss: 0.144\n",
            "Epoch: 25 Loss: 0.139\n",
            "Epoch: 26 Loss: 0.137\n",
            "Epoch: 27 Loss: 0.127\n",
            "Epoch: 28 Loss: 0.147\n",
            "Epoch: 29 Loss: 0.144\n",
            "Epoch: 30 Loss: 0.144\n",
            "Epoch: 31 Loss: 0.139\n",
            "Epoch: 32 Loss: 0.149\n",
            "Epoch: 33 Loss: 0.144\n",
            "Epoch: 34 Loss: 0.152\n",
            "Epoch: 35 Loss: 0.149\n",
            "Epoch: 36 Loss: 0.149\n",
            "Epoch: 37 Loss: 0.149\n",
            "Epoch: 38 Loss: 0.149\n",
            "Epoch: 39 Loss: 0.149\n",
            "Epoch: 40 Loss: 0.152\n",
            "Epoch: 41 Loss: 0.144\n",
            "Epoch: 42 Loss: 0.139\n",
            "Epoch: 43 Loss: 0.144\n",
            "Epoch: 44 Loss: 0.147\n",
            "Epoch: 45 Loss: 0.142\n",
            "Epoch: 46 Loss: 0.144\n",
            "Epoch: 47 Loss: 0.147\n",
            "Epoch: 48 Loss: 0.137\n",
            "Epoch: 49 Loss: 0.139\n",
            "Test Loss: 0.271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o7hj02oCxlL"
      },
      "source": [
        "class TripletMNIST():\n",
        "    \"\"\"\n",
        "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
        "    Test: Creates fixed triplets for testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mnist_dataset):\n",
        "        self.mnist_dataset = mnist_dataset\n",
        "        self.train = self.mnist_dataset.train\n",
        "        self.transform = self.mnist_dataset.transform\n",
        "\n",
        "        if self.train:\n",
        "            self.train_labels = self.mnist_dataset.train_labels\n",
        "            self.train_data = self.mnist_dataset.train_data\n",
        "            self.labels_set = set(self.train_labels.numpy())\n",
        "            self.label_to_indices = {label: np.where(self.train_labels.numpy() == label)[0]\n",
        "                                     for label in self.labels_set}\n",
        "\n",
        "        else:\n",
        "            self.test_labels = self.mnist_dataset.test_labels\n",
        "            self.test_data = self.mnist_dataset.test_data\n",
        "            # generate fixed triplets for testing\n",
        "            self.labels_set = set(self.test_labels.numpy())\n",
        "            self.label_to_indices = {label: np.where(self.test_labels.numpy() == label)[0]\n",
        "                                     for label in self.labels_set}\n",
        "\n",
        "            random_state = np.random.RandomState(29)\n",
        "\n",
        "            triplets = [[i,\n",
        "                         random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
        "                         random_state.choice(self.label_to_indices[\n",
        "                                                 np.random.choice(\n",
        "                                                     list(self.labels_set - set([self.test_labels[i].item()]))\n",
        "                                                 )\n",
        "                                             ])\n",
        "                         ]\n",
        "                        for i in range(len(self.test_data))]\n",
        "            self.test_triplets = triplets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            img1, label1 = self.train_data[index], self.train_labels[index].item()\n",
        "            positive_index = index\n",
        "            while positive_index == index:\n",
        "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
        "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
        "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
        "            img2 = self.train_data[positive_index]\n",
        "            img3 = self.train_data[negative_index]\n",
        "        else:\n",
        "            img1 = self.test_data[self.test_triplets[index][0]]\n",
        "            img2 = self.test_data[self.test_triplets[index][1]]\n",
        "            img3 = self.test_data[self.test_triplets[index][2]]\n",
        "\n",
        "        img1 = Image.fromarray(img1.numpy(), mode='L')\n",
        "        img2 = Image.fromarray(img2.numpy(), mode='L')\n",
        "        img3 = Image.fromarray(img3.numpy(), mode='L')\n",
        "        if self.transform is not None:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "            img3 = self.transform(img3)\n",
        "        return (img1, img2, img3), []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mnist_dataset)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECktQrA2HXKk",
        "outputId": "344c80c2-9bc0-41fe-e8d6-20a90a1e1e1c"
      },
      "source": [
        "trans = transforms.Compose([transforms.ToTensor()])\n",
        "trainloader = TripletMNIST(torchvision.datasets.MNIST(root=\"~/torch_datasets\", train = True, transform = trans, download=True))\n",
        "testloader = TripletMNIST(torchvision.datasets.MNIST(root=\"~/torch_datasets\", train = False, transform = trans, download=True))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:54: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:64: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:59: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:69: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVik_zjHFqi-"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class TripletModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TripletModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 300)\n",
        "        self.fc2 = nn.Linear(300, 300)\n",
        "        self.fc3 = nn.Linear(300, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        y1 =  self.fc4(F.relu(self.fc3( F.relu(self.fc2 (F.relu(self.fc1(x1)))))))\n",
        "        y2 =  self.fc4(F.relu(self.fc3(F.relu(self.fc2 (F.relu(self.fc1(x2)))))))\n",
        "        y3 =  self.fc4(F.relu(self.fc3( F.relu(self.fc2 (F.relu(self.fc1(x3)))))))\n",
        "        return y1, y2, y3"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuMkvHvOHmor"
      },
      "source": [
        "def train(model,optimizer,criterion,epoch):\n",
        "    for epch in range(epoch):\n",
        "      running_loss = 0\n",
        "      for i, data in enumerate(trainloader,0):\n",
        "        images = data\n",
        "        imgLst = list(images[0]) \n",
        "        optimizer.zero_grad()\n",
        "        imgLst[0] = imgLst[0].reshape(-1,784)\n",
        "        imgLst[1] = imgLst[1].reshape(-1,784)\n",
        "        imgLst[2] = imgLst[2].reshape(-1,784)\n",
        "        y1,y2,y3 = model(imgLst[0],imgLst[1],imgLst[2])\n",
        "        loss = criterion( y1,y2,y3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "      running_loss/= len(trainloader)\n",
        "      # print('Average  train loss: {:.3f} , epoch: {}'.format(running_loss,epch))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wqyRHVfJAdv"
      },
      "source": [
        "def test(model,criterion):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(testloader):\n",
        "      imgLst = list(data)\n",
        "      imgLst[0] = imgLst[0].reshape(-1,784)\n",
        "      imgLst[1] = imgLst[1].reshape(-1,784)\n",
        "      imgLst[2] = imgLst[2].reshape(-1,784)\n",
        "      y1,y2,y3 = model(imgLst[0],imgLst[1],imgLst[2])\n",
        "      loss = criterion(y1,y2,y3)\n",
        "      running_loss+=loss.item()\n",
        "    print('Average test loss: {:.3f} '.format(running_loss/len(testloader)))\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXB8YhzjLJhO",
        "outputId": "b3602e86-ba0d-4ed2-94d6-d5447ade384e"
      },
      "source": [
        "# Rmsprop\n",
        "tp = TripletModel()\n",
        "criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "optimizer = torch.optim.RMSprop(tp.parameters(), lr=0.01)\n",
        "train(tp,optimizer,criterion,5)\n",
        "test(tp,criterion)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average  train loss: 7.702 , epoch: 0\n",
            "Average  train loss: 1.400 , epoch: 1\n",
            "Average  train loss: 1.237 , epoch: 2\n",
            "Average  train loss: 1.003 , epoch: 3\n",
            "Average  train loss: 1.000 , epoch: 4\n",
            "Average test loss: 1.000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGkwebs0PaKs",
        "outputId": "51c791d6-6983-45af-baee-10540957ada1"
      },
      "source": [
        "# Sgd\n",
        "tp = TripletModel()\n",
        "criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "optimizer = torch.optim.SGD(tp.parameters(), lr=0.01)\n",
        "train(tp,optimizer,criterion,20)\n",
        "test(tp,criterion)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average  train loss: 1.001 , epoch: 0\n",
            "Average  train loss: 1.001 , epoch: 1\n",
            "Average  train loss: 1.000 , epoch: 2\n",
            "Average  train loss: 1.004 , epoch: 3\n",
            "Average  train loss: 0.997 , epoch: 4\n",
            "Average  train loss: 1.004 , epoch: 5\n",
            "Average  train loss: 1.002 , epoch: 6\n",
            "Average  train loss: 0.998 , epoch: 7\n",
            "Average  train loss: 0.992 , epoch: 8\n",
            "Average  train loss: 1.011 , epoch: 9\n",
            "Average  train loss: 1.000 , epoch: 10\n",
            "Average  train loss: 1.003 , epoch: 11\n",
            "Average  train loss: 0.984 , epoch: 12\n",
            "Average  train loss: 0.988 , epoch: 13\n",
            "Average  train loss: 1.010 , epoch: 14\n",
            "Average  train loss: 1.005 , epoch: 15\n",
            "Average  train loss: 1.001 , epoch: 16\n",
            "Average  train loss: 1.002 , epoch: 17\n",
            "Average  train loss: 1.000 , epoch: 18\n",
            "Average  train loss: 1.001 , epoch: 19\n",
            "Average test loss: 1.001 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hdVj3c2O8hh",
        "outputId": "12767234-6fd1-407d-cd14-d7575929c3ec"
      },
      "source": [
        "# ada-delta\n",
        "tp = TripletModel()\n",
        "criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "optimizer = torch.optim.Adadelta(tp.parameters(), lr=0.001)\n",
        "train(tp,optimizer,criterion,3)\n",
        "test(tp,criterion)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average  train loss: 1.000 , epoch: 0\n",
            "Average  train loss: 0.929 , epoch: 1\n",
            "Average  train loss: 0.848 , epoch: 2\n",
            "Average test loss: 0.972 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcGCBhu8fjSp",
        "outputId": "c76e6977-8a46-4ac4-fb67-ba34ecf7d1d2"
      },
      "source": [
        "p_range=[1,2,3,4,5]\n",
        "margin_range=[1.0,2.0,3.0,4.0,5.0]\n",
        "for p in p_range:\n",
        "  for m in margin_range:\n",
        "    tp = TripletModel()\n",
        "    criterion = nn.TripletMarginLoss(margin=m, p=p)\n",
        "    optimizer = torch.optim.RMSprop(tp.parameters())\n",
        "    train(tp,optimizer,criterion,5)\n",
        "    print('For p=',p,'margin=',m)\n",
        "    test(tp,criterion)\n",
        "# test/validation loss is minimized for p=3, margin=1.0"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For p= 1 margin= 1.0\n",
            "Average test loss: 1.000 \n",
            "For p= 1 margin= 2.0\n",
            "Average test loss: 2.000 \n",
            "For p= 1 margin= 3.0\n",
            "Average test loss: 3.000 \n",
            "For p= 1 margin= 4.0\n",
            "Average test loss: 4.000 \n",
            "For p= 1 margin= 5.0\n",
            "Average test loss: 10.986 \n",
            "For p= 2 margin= 1.0\n",
            "Average test loss: 1.000 \n",
            "For p= 2 margin= 2.0\n",
            "Average test loss: 1.869 \n",
            "For p= 2 margin= 3.0\n",
            "Average test loss: 3.295 \n",
            "For p= 2 margin= 4.0\n",
            "Average test loss: 4.000 \n",
            "For p= 2 margin= 5.0\n",
            "Average test loss: 20.612 \n",
            "For p= 3 margin= 1.0\n",
            "Average test loss: 0.969 \n",
            "For p= 3 margin= 2.0\n",
            "Average test loss: 1.972 \n",
            "For p= 3 margin= 3.0\n",
            "Average test loss: 5.297 \n",
            "For p= 3 margin= 4.0\n",
            "Average test loss: 3.637 \n",
            "For p= 3 margin= 5.0\n",
            "Average test loss: 5.139 \n",
            "For p= 4 margin= 1.0\n",
            "Average test loss: 1.000 \n",
            "For p= 4 margin= 2.0\n",
            "Average test loss: 2.069 \n",
            "For p= 4 margin= 3.0\n",
            "Average test loss: 3.262 \n",
            "For p= 4 margin= 4.0\n",
            "Average test loss: 3.980 \n",
            "For p= 4 margin= 5.0\n",
            "Average test loss: 5.000 \n",
            "For p= 5 margin= 1.0\n",
            "Average test loss: 1.000 \n",
            "For p= 5 margin= 2.0\n",
            "Average test loss: 2.023 \n",
            "For p= 5 margin= 3.0\n",
            "Average test loss: 6.057 \n",
            "For p= 5 margin= 4.0\n",
            "Average test loss: 4.000 \n",
            "For p= 5 margin= 5.0\n",
            "Average test loss: 5.000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrzbCUPTe0Qm"
      },
      "source": [
        "# Pro\n",
        "# 1)Siamese seem best suited for cases where we can have only a few examples per Class\n",
        "# 2 Learning from Semantic Similarity b/w two comparable things\n",
        "\n",
        "# Cons\n",
        "# 1)Doesn't ouput probabilities\n",
        "# 2 Reuires large training time\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}